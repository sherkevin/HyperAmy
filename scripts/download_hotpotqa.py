#!/usr/bin/env python
"""
ä¸‹è½½å’Œå‡†å¤‡ HotpotQA æ•°æ®é›†

ä» HuggingFace ä¸‹è½½ HotpotQA æ•°æ®é›†å¹¶è½¬æ¢ä¸ºé¡¹ç›®æ ¼å¼
"""
import os
import json
from typing import List, Dict

try:
    from datasets import load_dataset
    HAS_DATASETS = True
except ImportError:
    HAS_DATASETS = False
    print("âš ï¸  datasets åº“æœªå®‰è£…ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ–¹æ³•")

def download_hotpotqa(num_examples: int = 100):
    """
    ä¸‹è½½ HotpotQA æ•°æ®é›†
    
    Args:
        num_examples: ä¸‹è½½çš„æ ·æœ¬æ•°é‡ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
    """
    dataset_dir = os.path.join(os.path.dirname(__file__), '..', 'hipporag', 'reproduce', 'dataset')
    os.makedirs(dataset_dir, exist_ok=True)
    
    corpus_path = os.path.join(dataset_dir, "hotpotqa_corpus.json")
    qa_path = os.path.join(dataset_dir, "hotpotqa.json")
    
    if HAS_DATASETS:
        print("ä» HuggingFace ä¸‹è½½ HotpotQA æ•°æ®é›†...")
        try:
            # ä¸‹è½½ dev é›†ï¼ˆè¾ƒå°ï¼Œé€‚åˆæµ‹è¯•ï¼‰
            dataset = load_dataset("hotpot_qa", "distractor", split="validation")
            print(f"   âœ… ä¸‹è½½æˆåŠŸ: {len(dataset)} ä¸ªæ ·æœ¬")
            
            # é™åˆ¶æ ·æœ¬æ•°é‡ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
            if num_examples > 0:
                dataset = dataset.select(range(min(num_examples, len(dataset))))
                print(f"   âœ… ä½¿ç”¨å‰ {len(dataset)} ä¸ªæ ·æœ¬")
            
            # æå–è¯­æ–™åº“ï¼ˆæ‰€æœ‰æ–‡æ¡£ï¼‰
            corpus_dict = {}
            qa_samples = []
            
            for example in dataset:
                try:
                    # æå–é—®é¢˜å’Œç­”æ¡ˆ
                    question = example['question']
                    answer = example['answer']
                    
                    # æå–ç›¸å…³æ–‡æ¡£ï¼ˆsupporting factsï¼‰
                    supporting_facts = example.get('supporting_facts', [])
                    context = example.get('context', {})
                    
                    # HotpotQA çš„ context æ˜¯ dictï¼ŒåŒ…å« 'title' å’Œ 'sentences' åˆ—è¡¨
                    if not isinstance(context, dict):
                        continue
                    
                    titles = context.get('title', [])
                    sentences_list = context.get('sentences', [])
                    
                    # æ„å»ºæ ‡é¢˜åˆ°å¥å­çš„æ˜ å°„
                    title_to_sentences = {}
                    for i, title in enumerate(titles):
                        if i < len(sentences_list):
                            # sentences_list[i] æ˜¯ä¸€ä¸ªå¥å­åˆ—è¡¨
                            sents = sentences_list[i] if isinstance(sentences_list[i], list) else [str(sentences_list[i])]
                            title_to_sentences[title] = sents
                    
                    # æ„å»ºç›¸å…³æ–‡æ¡£åˆ—è¡¨ï¼ˆgold_docsï¼‰- ä½¿ç”¨ supporting_facts
                    relevant_docs = []
                    if supporting_facts:
                        for fact in supporting_facts:
                            if isinstance(fact, (list, tuple)) and len(fact) >= 2:
                                title = str(fact[0])
                                sent_idx = fact[1]
                                if title in title_to_sentences:
                                    sents = title_to_sentences[title]
                                    if isinstance(sent_idx, int) and 0 <= sent_idx < len(sents):
                                        # ä½¿ç”¨å•ä¸ªå¥å­ä½œä¸ºæ–‡æ¡£
                                        doc_text = f"{title}\n{sents[sent_idx]}"
                                        if doc_text not in relevant_docs:
                                            relevant_docs.append(doc_text)
                    
                    # å¦‚æœæ²¡æœ‰ supporting_factsï¼Œä½¿ç”¨æ‰€æœ‰æ–‡æ¡£
                    if not relevant_docs:
                        for title, sents in title_to_sentences.items():
                            doc_text = f"{title}\n{' '.join(sents)}"
                            relevant_docs.append(doc_text)
                    
                    qa_samples.append({
                        "question": question,
                        "answer": answer,
                        "relevant_docs": relevant_docs[:5]  # æœ€å¤š5ä¸ªç›¸å…³æ–‡æ¡£
                    })
                    
                    # æ”¶é›†æ‰€æœ‰æ–‡æ¡£åˆ°è¯­æ–™åº“
                    for title, sents in title_to_sentences.items():
                        doc_text = f"{title}\n{' '.join(sents)}"
                        doc_id = f"{title}_{abs(hash(doc_text)) % 1000000}"
                        if doc_id not in corpus_dict:
                            corpus_dict[doc_id] = {
                                "title": title,
                                "text": ' '.join(sents)
                            }
                except Exception as e:
                    print(f"   âš ï¸  å¤„ç†æ ·æœ¬æ—¶å‡ºé”™: {e}")
                    import traceback
                    traceback.print_exc()
                    continue
            
            # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
            corpus = list(corpus_dict.values())
            
            # ä¿å­˜è¯­æ–™åº“
            with open(corpus_path, 'w', encoding='utf-8') as f:
                json.dump(corpus, f, ensure_ascii=False, indent=2)
            print(f"   âœ… è¯­æ–™åº“å·²ä¿å­˜: {len(corpus)} ä¸ªæ–‡æ¡£ -> {corpus_path}")
            
            # ä¿å­˜ QA æ•°æ®
            with open(qa_path, 'w', encoding='utf-8') as f:
                json.dump(qa_samples, f, ensure_ascii=False, indent=2)
            print(f"   âœ… QA æ•°æ®å·²ä¿å­˜: {len(qa_samples)} ä¸ªé—®é¢˜ -> {qa_path}")
            
            return corpus, qa_samples
            
        except Exception as e:
            print(f"   âŒ ä¸‹è½½å¤±è´¥: {e}")
            print(f"   âš ï¸  å°†ä½¿ç”¨ç°æœ‰æ•°æ®é›†æˆ–åˆ›å»ºç¤ºä¾‹æ•°æ®é›†")
            return None, None
    else:
        print("âš ï¸  datasets åº“æœªå®‰è£…ï¼Œæ— æ³•è‡ªåŠ¨ä¸‹è½½")
        print(f"   è¯·æ‰‹åŠ¨ä¸‹è½½ HotpotQA æ•°æ®é›†æˆ–å®‰è£…: pip install datasets")
        return None, None

if __name__ == "__main__":
    import sys
    
    print("=" * 70)
    print("HotpotQA æ•°æ®é›†ä¸‹è½½å’Œå‡†å¤‡")
    print("=" * 70)
    
    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°ï¼špython download_hotpotqa.py [num_examples]
    # num_examples=0 è¡¨ç¤ºä¸‹è½½å®Œæ•´æ•°æ®é›†
    if len(sys.argv) > 1:
        try:
            num_examples = int(sys.argv[1])
            if num_examples == 0:
                print("ğŸ“¥ ä¸‹è½½å®Œæ•´ HotpotQA æ•°æ®é›†...")
            else:
                print(f"ğŸ“¥ ä¸‹è½½å‰ {num_examples} ä¸ªæ ·æœ¬...")
        except ValueError:
            print("âš ï¸  å‚æ•°æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼ˆå®Œæ•´æ•°æ®é›†ï¼‰")
            num_examples = 0
    else:
        # é»˜è®¤ä¸‹è½½å®Œæ•´æ•°æ®é›†
        num_examples = 0
        print("ğŸ“¥ ä¸‹è½½å®Œæ•´ HotpotQA æ•°æ®é›†ï¼ˆé»˜è®¤ï¼‰...")
        print("   æç¤º: å¯ä»¥ä¼ å…¥å‚æ•°æŒ‡å®šæ•°é‡ï¼Œå¦‚: python download_hotpotqa.py 100")
    
    # ä¸‹è½½æ•°æ®é›†
    corpus, qa_samples = download_hotpotqa(num_examples=num_examples)
    
    if corpus and qa_samples:
        print(f"\nâœ… æ•°æ®é›†å‡†å¤‡å®Œæˆ!")
        print(f"   è¯­æ–™åº“: {len(corpus)} ä¸ªæ–‡æ¡£")
        print(f"   QA æ•°æ®: {len(qa_samples)} ä¸ªé—®é¢˜")
        
        # è®¡ç®—æ–‡ä»¶å¤§å°
        import os
        corpus_path = os.path.join(os.path.dirname(__file__), '..', 'hipporag', 'reproduce', 'dataset', 'hotpotqa_corpus.json')
        qa_path = os.path.join(os.path.dirname(__file__), '..', 'hipporag', 'reproduce', 'dataset', 'hotpotqa.json')
        if os.path.exists(corpus_path):
            size_mb = os.path.getsize(corpus_path) / (1024 * 1024)
            print(f"   è¯­æ–™åº“æ–‡ä»¶å¤§å°: {size_mb:.2f} MB")
        if os.path.exists(qa_path):
            size_mb = os.path.getsize(qa_path) / (1024 * 1024)
            print(f"   QA æ–‡ä»¶å¤§å°: {size_mb:.2f} MB")
    else:
        print(f"\nâš ï¸  æ•°æ®é›†å‡†å¤‡å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ‰‹åŠ¨ä¸‹è½½")

