#!/usr/bin/env python3
"""
èåˆæ£€ç´¢å¯¹æ¯”æµ‹è¯• - è¯¦ç»†ç‰ˆ

è¾“å‡ºæ¯ä¸ªæ£€ç´¢æ¨¡å—çš„å®Œæ•´ä¸Šä¸‹æ–‡åˆ—è¡¨ï¼Œä¾¿äºå¯¹æ¯”åˆ†æ
"""

import logging
import sys
import time
from pathlib import Path

# è®¾ç½®æ—¥å¿—æ–‡ä»¶
log_file = Path("./log/test_fusion_comparison_detailed.log")
log_file.parent.mkdir(exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(message)s',
    handlers=[
        logging.FileHandler(log_file, encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger(__name__)

from llm.config import API_KEY, BASE_URL, DEFAULT_EMBEDDING_MODEL, API_URL_EMBEDDINGS
import os
os.environ["OPENAI_API_KEY"] = API_KEY

from workflow.graph_fusion_retrieval import GraphFusionRetriever
from workflow.amygdala import Amygdala
from workflow.hipporag_wrapper import HippoRAGWrapper
from poincare.retrieval import HyperAmyRetrieval

print("=" * 120)
print("èåˆæ£€ç´¢å¯¹æ¯”æµ‹è¯•ï¼ˆè¯¦ç»†ç‰ˆï¼‰ï¼šGraphFusion vs HippoRAG vs Amygdala")
print("=" * 120)

# æµ‹è¯•æ•°æ®
chunks = [
    '"I have an excellent appetite," said Albert. "I hope, my dear Count, you have the same." '
    '"I?" said Monte Cristo. "I never eat, or rather, I eat so little that it is not worth '
    'talking about. I have my own peculiar habits."',

    'The Count took from his pocket a small case made of hollowed emerald, took out a small '
    'greenish pill, and swallowed it. "This is my food," he said to the guests. "With this, '
    'I feel neither hunger nor fatigue. It is a secret I learned in the East."',

    '"Will you not take anything?" asked Mercedes. "A peach? Some grapes?" '
    '"I thank you, Madame," replied Monte Cristo with a bow, "but I never eat between meals. '
    'It is a rule I have imposed upon myself to maintain my health."',

    '"In the countries of the East, where I have lived," said Monte Cristo to Franz, '
    '"people who eat and drink together are bound by a sacred tie. They become brothers. '
    'Therefore, I never eat or drink in the house of a man whom I wish to kill. '
    'If I shared their bread, I would be forbidden by honor to take my revenge."',

    'Mercedes looked at him with terror in her eyes. Her hand trembled as she held the plate. '
    '"You refuse?" she whispered, her voice full of tears. "Is it because you are our enemy? '
    'To refuse to break bread... means you bring death to this house." '
    'She realized then that the man standing before her was not just a visitor, but an avenger '
    'who remembered the past.'
]

chunk_types = {
    0: "æ—©é¤åœºæ™¯",
    1: "è¯ä¸¸åœºæ™¯",
    2: "æ‹’ç»è‘¡è„å¹²",
    3: "ä¸œæ–¹å“²å­¦ï¼ˆæ ¸å¿ƒç­”æ¡ˆï¼‰",
    4: "æƒ…æ„Ÿå¯¹å³™"
}

query = "Why did the Count strictly refuse the muscatel grapes and any refreshment offered by Madame de Morcerf (Mercedes) during his visit to her house?"

# ä½¿ç”¨å·²æœ‰çš„æ•°æ®åº“åˆå§‹åŒ–
print("\n" + "=" * 120)
print("ã€ä½¿ç”¨å·²æœ‰æ•°æ®åº“åˆå§‹åŒ–ç³»ç»Ÿã€‘")
print("=" * 120)

# èåˆæ£€ç´¢å™¨
print("\n[1/3] åŠ è½½å›¾è°±èåˆæ£€ç´¢å™¨...")
fusion = GraphFusionRetriever(
    amygdala_save_dir="./test_graph_fusion_amygdala_db",
    hipporag_save_dir="./test_graph_fusion_hipporag_db",
    llm_model_name="DeepSeek-V3.2",
    auto_link_particles=False
)
print("âœ“ å›¾è°±èåˆæ£€ç´¢å™¨åŠ è½½å®Œæˆ")

# HippoRAG
print("\n[2/3] åŠ è½½ HippoRAG...")
hipporag = HippoRAGWrapper(
    save_dir="./test_graph_fusion_hipporag_db",
    llm_model_name="DeepSeek-V3.2",
    llm_base_url=BASE_URL,
    embedding_model_name=f"VLLM/{DEFAULT_EMBEDDING_MODEL}",
    embedding_base_url=API_URL_EMBEDDINGS
)
print("âœ“ HippoRAG åŠ è½½å®Œæˆ")

# Amygdala
print("\n[3/3] åŠ è½½ Amygdala...")
amygdala = Amygdala(
    save_dir="./test_graph_fusion_amygdala_db",
    particle_collection_name="fusion_particles",
    conversation_namespace="fusion",
    auto_link_particles=False
)
print("âœ“ Amygdala åŠ è½½å®Œæˆ")

# è¾…åŠ©å‡½æ•°
def get_chunk_type(chunk_text):
    for i, chunk in enumerate(chunks):
        if chunk_text == chunk:
            return chunk_types[i]
    return "Unknown"

def format_chunk_output(rank, text, score, score_type="åˆ†æ•°"):
    """æ ¼å¼åŒ–å•ä¸ªchunkçš„è¾“å‡º"""
    chunk_type = get_chunk_type(text)
    output = f"\n{'=' * 120}\n"
    output += f"Rank {rank}: {chunk_type}\n"
    output += f"{'=' * 120}\n"
    output += f"{score_type}: {score}\n"
    output += f"{'â”€' * 120}\n"
    output += f"{text}\n"
    output += f"{'=' * 120}"
    return output

# ========== æµ‹è¯• 1: å›¾è°±èåˆæ£€ç´¢ ==========
print("\n" + "=" * 120)
print("ã€æµ‹è¯• 1ã€‘å›¾è°±èåˆæ£€ç´¢ï¼ˆGraphFusion: HippoRAG + Amygdalaï¼‰")
print("=" * 120)
print(f"\nQuery: {query}")
print("\næƒé‡é…ç½®: emotion=0.3, semantic=0.5, fact=0.2")

start_time = time.time()
fusion_results = fusion.retrieve(
    query=query,
    top_k=5,
    emotion_weight=0.3,
    semantic_weight=0.5,
    fact_weight=0.2
)
fusion_time = time.time() - start_time

print("\n" + "=" * 120)
print(f"ã€å›¾è°±èåˆæ£€ç´¢ç»“æœã€‘ï¼ˆæ£€ç´¢è€—æ—¶: {fusion_time:.2f}sï¼‰")
print("=" * 120)

for result in fusion_results:
    print(format_chunk_output(result['rank'], result['text'], result['score'], "PPRåˆ†æ•°"))

# ========== æµ‹è¯• 2: HippoRAG å•ç‹¬æ£€ç´¢ ==========
print("\n\n" + "=" * 120)
print("ã€æµ‹è¯• 2ã€‘HippoRAG å•ç‹¬æ£€ç´¢")
print("=" * 120)
print(f"\nQuery: {query}")

start_time = time.time()
hipporag_results_raw = hipporag.retrieve(query=query, top_k=5)
hipporag_time = time.time() - start_time

hipporag_results = []
for rank, result in enumerate(hipporag_results_raw):
    hipporag_results.append({
        'rank': rank + 1,
        'text': result['text'],
        'score': result['score']
    })

print("\n" + "=" * 120)
print(f"ã€HippoRAG æ£€ç´¢ç»“æœã€‘ï¼ˆæ£€ç´¢è€—æ—¶: {hipporag_time:.2f}sï¼‰")
print("=" * 120)

for result in hipporag_results:
    print(format_chunk_output(result['rank'], result['text'], result['score'], "PPRåˆ†æ•°"))

# ========== æµ‹è¯• 3: Amygdala å•ç‹¬æ£€ç´¢ ==========
print("\n\n" + "=" * 120)
print("ã€æµ‹è¯• 3ã€‘Amygdala å•ç‹¬æ£€ç´¢ï¼ˆåŒæ›²ç©ºé—´æƒ…ç»ªç›¸ä¼¼åº¦æ£€ç´¢ï¼‰")
print("=" * 120)
print(f"\nQuery: {query}")

start_time = time.time()
query_particles = amygdala.particle.process(
    text=query,
    text_id=f"query_{int(time.time())}"
)

amygdala_results = []
if query_particles:
    retriever = HyperAmyRetrieval(
        storage=amygdala.particle_storage,
        projector=amygdala.particle_projector
    )

    search_results = retriever.search(
        query_entity=query_particles[0],
        top_k=10,  # å¢åŠ top_kä»¥è·å¾—æ›´å¤šç»“æœ
        cone_width=100  # æ”¾å®½cone_width
    )

    # è·å–æ‰€æœ‰ conversation_id
    conversation_ids = [r.metadata.get("conversation_id", "") for r in search_results]

    # æ‰¹é‡è·å–å¯¹è¯æ–‡æœ¬
    if conversation_ids:
        conversations = amygdala.conversation_store.get_strings_by_ids(conversation_ids)

        # åˆ›å»º conversation_id åˆ°æ–‡æœ¬çš„æ˜ å°„
        conv_to_text = {}
        for conv in conversations:
            conv_id = conv.get('id', '')
            text = conv.get('text', '')
            if conv_id and text:
                conv_to_text[conv_id] = text

        # å»é‡ï¼šæ¯ä¸ªconversationåªä¿ç•™æœ€ç›¸å…³çš„ç»“æœ
        seen_conv_ids = set()
        for result in search_results:
            conv_id = result.metadata.get("conversation_id", "")
            if conv_id and conv_id not in seen_conv_id:
                chunk_text = conv_to_text.get(conv_id, "")
                if chunk_text:
                    amygdala_results.append({
                        'rank': len(amygdala_results) + 1,
                        'text': chunk_text,
                        'score': result.score
                    })
                    seen_conv_id = conv_id

            if len(amygdala_results) >= 5:
                break

amygdala_time = time.time() - start_time

print("\n" + "=" * 120)
print(f"ã€Amygdala æ£€ç´¢ç»“æœã€‘ï¼ˆæ£€ç´¢è€—æ—¶: {amygdala_time:.2f}sï¼‰")
print("=" * 120)

if amygdala_results:
    for result in amygdala_results:
        print(format_chunk_output(result['rank'], result['text'], result['score'], "åŒæ›²è·ç¦»ï¼ˆè¶Šå°è¶Šç›¸ä¼¼ï¼‰"))
else:
    print("æœªæ£€ç´¢åˆ°ç»“æœï¼ˆå¯èƒ½éœ€è¦è°ƒæ•´ cone_width æˆ–å…¶ä»–å‚æ•°ï¼‰")

# ========== è¯¦ç»†å¯¹æ¯”åˆ†æ ==========
print("\n\n" + "=" * 120)
print("ã€è¯¦ç»†å¯¹æ¯”åˆ†æã€‘")
print("=" * 120)

# å…³é”® chunks
key_chunks = {
    "æƒ…æ„Ÿå¯¹å³™": 4,
    "ä¸œæ–¹å“²å­¦": 3,
    "æ‹’ç»è‘¡è„å¹²": 2,
    "è¯ä¸¸åœºæ™¯": 1,
    "æ—©é¤åœºæ™¯": 0
}

all_modes = [
    ("å›¾è°±èåˆ", fusion_results),
    ("HippoRAG", hipporag_results),
    ("Amygdala", amygdala_results)
]

def get_rank(results, chunk_idx):
    for result in results:
        for i, chunk in enumerate(chunks):
            if result.get('text') == chunk and i == chunk_idx:
                return result['rank']
    return None

# 1. æ’åå¯¹æ¯”è¡¨æ ¼
print("\n" + "=" * 120)
print("1. æ’åå¯¹æ¯”è¡¨æ ¼")
print("=" * 120)

print(f"\n{'æ£€ç´¢æ–¹å¼':<20} {'æƒ…æ„Ÿå¯¹å³™':<15} {'ä¸œæ–¹å“²å­¦':<15} {'æ‹’ç»è‘¡è„å¹²':<15} {'è¯ä¸¸åœºæ™¯':<15} {'æ—©é¤åœºæ™¯':<15}")
print("â”€" * 110)

for mode_name, results in all_modes:
    row = f"{mode_name:<20}"
    for chunk_name, chunk_idx in key_chunks.items():
        rank = get_rank(results, chunk_idx)
        rank_str = f"Rank {rank}" if rank else "æœªæ£€ç´¢åˆ°"
        row += f"{rank_str:<15}"
    print(row)

# 2. å¹³å‡æ’åç»Ÿè®¡
print("\n" + "=" * 120)
print("2. å¹³å‡æ’åç»Ÿè®¡ï¼ˆè¶Šä½è¶Šå¥½ï¼‰")
print("=" * 120)

print(f"\n{'æ£€ç´¢æ–¹å¼':<20} {'å¹³å‡æ’å':<15} {'æ ‡å‡†å·®':<15} {'æ£€ç´¢åˆ°çš„chunks':<20}")
print("â”€" * 80)

for mode_name, results in all_modes:
    ranks_list = []
    for chunk_idx in key_chunks.values():
        rank = get_rank(results, chunk_idx)
        if rank:
            ranks_list.append(rank)

    if ranks_list:
        avg_rank = sum(ranks_list) / len(ranks_list)
        variance = sum((r - avg_rank) ** 2 for r in ranks_list) / len(ranks_list)
        std_dev = variance ** 0.5
        retrieved_count = len(results)
        print(f"{mode_name:<20} {avg_rank:<15.2f} {std_dev:<15.2f} {retrieved_count}/{len(chunks)}")
    else:
        print(f"{mode_name:<20} {'-':<15} {'-':<15} {len(results)}/{len(chunks)}")

# 3. Top-3 å‘½ä¸­ç‡ï¼ˆå…³é”®chunksï¼‰
print("\n" + "=" * 120)
print("3. Top-3 å‘½ä¸­ç‡ï¼ˆå…³é”® chunksï¼šæƒ…æ„Ÿå¯¹å³™ã€ä¸œæ–¹å“²å­¦ã€æ‹’ç»è‘¡è„å¹²ï¼‰")
print("=" * 120)

key_chunk_indices = [4, 3, 2]

print(f"\n{'æ£€ç´¢æ–¹å¼':<20} {'å‘½ä¸­æ•°':<15} {'å‘½ä¸­ç‡':<15} {'è¯¦æƒ…':<50}")
print("â”€" * 110)

for mode_name, results in all_modes:
    hits = []
    for chunk_idx in key_chunk_indices:
        rank = get_rank(results, chunk_idx)
        if rank:
            chunk_name = list(key_chunks.keys())[list(key_chunks.values()).index(chunk_idx)]
            hits.append(f"{chunk_name}=R{rank}")

    top_3_hits = sum(1 for chunk_idx in key_chunk_indices
                     if (rank := get_rank(results, chunk_idx)) and rank <= 3)
    hit_rate = top_3_hits / len(key_chunk_indices) * 100

    hits_str = ", ".join(hits) if hits else "æ— "
    print(f"{mode_name:<20} {top_3_hits}/{len(key_chunk_indices)}{'':<8} {hit_rate:<15.1f}% {hits_str:<50}")

# 4. Top-1 å‡†ç¡®ç‡ï¼ˆæƒ…æ„Ÿå¯¹å³™ - æœ€å…³é”®ç­”æ¡ˆï¼‰
print("\n" + "=" * 120)
print("4. Top-1 å‡†ç¡®ç‡ï¼ˆæƒ…æ„Ÿå¯¹å³™ - æœ€å…³é”®ç­”æ¡ˆï¼‰")
print("=" * 120)

target_chunk_idx = 4  # æƒ…æ„Ÿå¯¹å³™

print(f"\n{'æ£€ç´¢æ–¹å¼':<20} {'æ’å':<15} {'è¯„ä»·':<50}")
print("â”€" * 90)

for mode_name, results in all_modes:
    rank = get_rank(results, target_chunk_idx)
    if rank == 1:
        print(f"{mode_name:<20} Rank {rank:<10} âœ“âœ“âœ“ å®Œç¾ï¼æœ€å…³é”®ç­”æ¡ˆæ’åœ¨ç¬¬ä¸€ä½")
    elif rank:
        deviation = rank - 1
        print(f"{mode_name:<20} Rank {rank:<10} åå·® {rank-1} ä½ï¼ˆ{deviation if deviation <= 2 else deviation}ä½åç¦»ï¼‰")
    else:
        print(f"{mode_name:<20} {'-':<15} âœ— æœªæ£€ç´¢åˆ°æœ€å…³é”®ç­”æ¡ˆ")

# 5. æ£€ç´¢æ€§èƒ½å¯¹æ¯”
print("\n" + "=" * 120)
print("5. æ£€ç´¢æ€§èƒ½å¯¹æ¯”")
print("=" * 120)

times = [
    ("å›¾è°±èåˆ", fusion_time),
    ("HippoRAG", hipporag_time),
    ("Amygdala", amygdala_time)
]

min_time = min(t[1] for t in times)

print(f"\n{'æ£€ç´¢æ–¹å¼':<20} {'è€—æ—¶(s)':<15} {'ç›¸å¯¹å€æ•°':<15} {'æ€§èƒ½è¯„ä»·':<30}")
print("â”€" * 90)

for mode_name, time_cost in times:
    relative = time_cost / min_time
    if relative <= 1.5:
        perf_eval = "ä¼˜ç§€"
    elif relative <= 3:
        perf_eval = "è‰¯å¥½"
    elif relative <= 10:
        perf_eval = "ä¸€èˆ¬"
    else:
        perf_eval = "è¾ƒæ…¢"
    print(f"{mode_name:<20} {time_cost:<15.2f} {relative:<15.2f}x {perf_eval:<30}")

# ========== æ€»ç»“åˆ†æ ==========
print("\n\n" + "=" * 120)
print("ã€æ€»ç»“åˆ†æã€‘")
print("=" * 120)

print("\nğŸ“Š æ£€ç´¢æ•ˆæœæ€»ç»“:")

# è®¡ç®—å„é¡¹æŒ‡æ ‡
metrics = {}

for mode_name, results in all_modes:
    # å¹³å‡æ’å
    ranks_list = []
    for chunk_idx in key_chunks.values():
        rank = get_rank(results, chunk_idx)
        if rank:
            ranks_list.append(rank)

    if ranks_list:
        avg_rank = sum(ranks_list) / len(ranks_list)

        # Top-3 å‘½ä¸­ç‡
        top_3_hits = sum(1 for chunk_idx in key_chunk_indices
                        if (rank := get_rank(results, chunk_idx)) and rank <= 3)
        hit_rate = top_3_hits / len(key_chunk_indices) * 100

        # Top-1 å‡†ç¡®ç‡
        top_1_acc = 1.0 if get_rank(results, 4) == 1 else 0.0

        metrics[mode_name] = {
            'avg_rank': avg_rank,
            'top3_hit_rate': hit_rate,
            'top1_accuracy': top_1_acc,
            'retrieved_count': len(results)
        }

print(f"\n{'æ£€ç´¢æ–¹å¼':<20} {'å¹³å‡æ’å':<12} {'Top-3å‘½ä¸­ç‡':<15} {'Top-1å‡†ç¡®ç‡':<12} {'æ£€ç´¢åˆ°chunks':<15}")
print("â”€" * 90)

for mode_name, metric in metrics.items():
    print(f"{mode_name:<20} {metric['avg_rank']:<12.2f} "
               f"{metric['top3_hit_rate']:<15.1f}% {metric['top1_accuracy']:<12.1f}% "
               f"{metric['retrieved_count']}/{len(chunks)}")

# æ¨èå»ºè®®
print("\n[ä½¿ç”¨å»ºè®®]")

best_avg_rank = min(metrics.items(), key=lambda x: x[1]['avg_rank']) if metrics else None
if best_avg_rank:
    print(f"  â€¢ è¿½æ±‚æ£€ç´¢è´¨é‡ï¼ˆå¹³å‡æ’åæœ€ä¼˜ï¼‰: {best_avg_rank[0]} (å¹³å‡æ’å: {best_avg_rank[1]['avg_rank']:.2f})")

best_top1 = max(metrics.items(), key=lambda x: x[1]['top1_accuracy']) if metrics else None
if best_top1:
    print(f"  â€¢ è¿½æ±‚æœ€ä½³ç­”æ¡ˆï¼ˆTop-1å‡†ç¡®ç‡æœ€é«˜ï¼‰: {best_top1[0]} (Top-1 å‡†ç¡®ç‡: {best_top1[1]['top1_accuracy']:.1%})")

fastest = min(times, key=lambda x: x[1])
print(f"  â€¢ è¿½æ±‚æ£€ç´¢é€Ÿåº¦: {fastest[0]} (è€—æ—¶: {fastest[1]:.2f}s)")

best_top3 = max(metrics.items(), key=lambda x: x[1]['top3_hit_rate']) if metrics else None
if best_top3:
    print(f"  â€¢ è¿½æ±‚ç¨³å®šæ€§ï¼ˆTop-3å‘½ä¸­ç‡æœ€é«˜ï¼‰: {best_top3[0]} (Top-3 å‘½ä¸­ç‡: {best_top3[1]['top3_hit_rate']:.1f}%)")

# ç»¼åˆè¯„åˆ†
print("\nğŸ¯ ç»¼åˆè¯„åˆ†ï¼ˆæ»¡åˆ†100ï¼‰:")

for mode_name, metric in metrics.items():
    # å½’ä¸€åŒ–è¯„åˆ†ï¼ˆ0-100ï¼‰
    rank_score = (6 - metric['avg_rank']) / 5 * 40  # å¹³å‡æ’åè¯„åˆ†ï¼ˆ0-40ï¼‰
    top3_score = metric['top3_hit_rate'] * 0.4  # Top-3 å‘½ä¸­ç‡è¯„åˆ†ï¼ˆ0-40ï¼‰
    top1_score = metric['top1_accuracy'] * 20  # Top-1 å‡†ç¡®ç‡è¯„åˆ†ï¼ˆ0-20ï¼‰

    total_score = rank_score + top3_score + top1_score
    print(f"  {mode_name}: {total_score:.1f}/100")

print("\n" + "=" * 120)
print("æµ‹è¯•å®Œæˆï¼")
print("=" * 120)
print(f"\nè¯¦ç»†æ—¥å¿—å·²ä¿å­˜åˆ°: {log_file}")
print("\nä¸»è¦ç»“è®ºå·²åœ¨ä¸Šé¢çš„è¾“å‡ºä¸­å±•ç¤ºï¼ŒåŒ…æ‹¬ä¸‰ä¸ªæ£€ç´¢æ¨¡å—çš„å®Œæ•´ä¸Šä¸‹æ–‡åˆ—è¡¨å’Œè¯¦ç»†å¯¹æ¯”åˆ†æã€‚")
