# HyperAmy

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

HyperAmy is an emotion-enhanced RAG framework built on top of [HippoRAG](https://github.com/OSU-NLP-Group/HippoRAG), integrating emotion analysis capabilities to enable LLMs to understand and leverage emotional context in retrieval-augmented generation tasks.

```
HyperAmy/
‚îú‚îÄ‚îÄ llm/                    # LLM ÂÆ¢Êà∑Á´ØÊ®°Âùó
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py         # Ê®°ÂùóÂØºÂá∫
‚îÇ   ‚îú‚îÄ‚îÄ config.py           # ÈÖçÁΩÆÁÆ°ÁêÜÔºà‰ªé .env ËØªÂèñ API_KEY Âíå BASE_URLÔºâ
‚îÇ   ‚îú‚îÄ‚îÄ completion_client.py # LLM ÂÆ¢Êà∑Á´ØÔºàÊîØÊåÅ normal Âíå specific ‰∏§ÁßçÊ®°ÂºèÔºâ
‚îÇ   ‚îî‚îÄ‚îÄ README.md           # LLM Ê®°ÂùóËØ¶ÁªÜÊñáÊ°£
‚îÇ
‚îú‚îÄ‚îÄ point_label/            # ÁÇπÊ†áÁ≠æÊ®°ÂùóÔºàÊÉÖÊÑü„ÄÅËÆ∞ÂøÜÊ∑±Â∫¶„ÄÅÊ∏©Â∫¶„ÄÅÊÉäËÆ∂ÂÄºÔºâ
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ emotion.py          # ÊÉÖÊÑüÂêëÈáèÊèêÂèñÔºàËæìÂÖ• chunkÔºåËæìÂá∫ emotion vectorÔºâ
‚îÇ   ‚îú‚îÄ‚îÄ labels.py           # ËÆ∞ÂøÜÊ∑±Â∫¶ÂíåÊ∏©Â∫¶ËÆ°ÁÆóÔºàemotion vector, memory_depth, temperatureÔºâ
‚îÇ   ‚îú‚îÄ‚îÄ speed.py            # ÊÉäËÆ∂ÂÄºËÆ°ÁÆóÔºàsurprise valueÔºåÂü∫‰∫é token Ê¶ÇÁéáÔºâ
‚îÇ   ‚îî‚îÄ‚îÄ temperature.py     # Ê∏©Â∫¶ËÆ°ÁÆóÔºàÂæÖÂÆûÁé∞Ôºâ
‚îÇ
‚îú‚îÄ‚îÄ poincare/               # ÂèåÊõ≤Á©∫Èó¥Â≠òÂÇ®‰∏éÊ£ÄÁ¥¢Ê®°Âùó
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ types.py            # Êï∞ÊçÆÁ±ªÂûãÂÆö‰πâÔºàPoint, SearchResultÔºâ
‚îÇ   ‚îú‚îÄ‚îÄ physics.py          # ÂèåÊõ≤Á©∫Èó¥Áâ©ÁêÜËÆ°ÁÆóÔºàTimePhysics, ParticleProjectorÔºâ
‚îÇ   ‚îú‚îÄ‚îÄ storage.py          # ÂèåÊõ≤Á©∫Èó¥Â≠òÂÇ®ÔºàHyperAmyStorageÔºâ
‚îÇ   ‚îú‚îÄ‚îÄ retrieval.py        # ÂèåÊõ≤Á©∫Èó¥Ê£ÄÁ¥¢ÔºàHyperAmyRetrievalÔºâ
‚îÇ   ‚îî‚îÄ‚îÄ linking.py          # ÂèåÊõ≤Á©∫Èó¥ÈìæÊé•ÊûÑÂª∫
‚îÇ
‚îú‚îÄ‚îÄ sentiment/              # ÊÉÖÊÑüÂàÜÊûêÊ®°ÂùóÔºàÊóßÁâàÔºå‰øùÁïôÂÖºÂÆπÔºâ
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ emotion_vector.py   # ÊÉÖÊÑüÂêëÈáèÊèêÂèñ
‚îÇ   ‚îú‚îÄ‚îÄ emotion_store.py    # ÊÉÖÊÑüÂêëÈáèÂ≠òÂÇ®ÂíåÁÆ°ÁêÜ
‚îÇ   ‚îî‚îÄ‚îÄ hipporag_enhanced.py # HippoRAG Â¢ûÂº∫ÁâàÔºàÈõÜÊàêÊÉÖÊÑüÂàÜÊûêÔºâ
‚îÇ
‚îú‚îÄ‚îÄ utils/                  # Â∑•ÂÖ∑Ê®°Âùó
‚îÇ   ‚îî‚îÄ‚îÄ extract_entitiy.py  # ÂÆû‰ΩìÊäΩÂèñÔºàÂü∫‰∫é HippoRAG ÁöÑ OpenIEÔºâ
‚îÇ
‚îî‚îÄ‚îÄ test/                   # ÊµãËØïÊñá‰ª∂
    ‚îú‚îÄ‚îÄ test_infer.py       # ÊµãËØïÊé®ÁêÜÂíå token Ê¶ÇÁéáÂàÜÊûê
    ‚îú‚îÄ‚îÄ test_completion_client.py # ÊµãËØï Completion Client ÂäüËÉΩ
    ‚îú‚îÄ‚îÄ test_emotion.py     # ÊµãËØïÊÉÖÊÑüÂêëÈáèÊèêÂèñ
    ‚îú‚îÄ‚îÄ test_bge.py         # ÊµãËØï BGE ÂµåÂÖ•ÂíåÊÉÖÊÑüÊèèËø∞
    ‚îú‚îÄ‚îÄ test_integration.py # ÊµãËØï HippoRAG Êï¥Âêà
    ‚îú‚îÄ‚îÄ test_dataset_integration.py # ÊµãËØïÊï∞ÊçÆÈõÜÊï¥Âêà
    ‚îú‚îÄ‚îÄ test_labels.py     # ÊµãËØïËÆ∞ÂøÜÊ∑±Â∫¶ÂíåÊ∏©Â∫¶ËÆ°ÁÆó
    ‚îú‚îÄ‚îÄ test_speed.py       # ÊµãËØïÊÉäËÆ∂ÂÄºËÆ°ÁÆó
    ‚îú‚îÄ‚îÄ test_entity.py     # ÊµãËØïÂÆû‰ΩìÊäΩÂèñ
    ‚îú‚îÄ‚îÄ test_poincare.py   # ÊµãËØïÂèåÊõ≤Á©∫Èó¥Â≠òÂÇ®ÂíåÊ£ÄÁ¥¢
    ‚îî‚îÄ‚îÄ test_linking.py    # ÊµãËØïÂèåÊõ≤Á©∫Èó¥ÈìæÊé•
```

HyperAmy extends HippoRAG with emotion-aware capabilities:

- **Emotion-Enhanced Retrieval**: Combines semantic and emotional similarity for more contextually relevant document retrieval
- **Emotion Vector Extraction**: Extracts 28-dimensional emotion vectors from text using LLMs
- **Emotion-Aware RAG**: Integrates emotional understanding into the RAG pipeline for improved answer quality
- **Token-Level Probability Analysis**: Supports detailed token-level probability analysis for LLM outputs

## Features

- üß† **Emotion Analysis**: Extract and quantify emotional content from text
- üîç **Emotion-Enhanced Retrieval**: Combine semantic and emotional similarity for better retrieval
- üìä **Emotion Vectors**: 28-dimensional emotion vectors based on Plutchik's emotion wheel
- üîÑ **Seamless Integration**: Built on HippoRAG framework with minimal changes
- üéØ **Token Probability**: Support for token-level probability analysis
- üíæ **Persistent Storage**: Efficient storage of emotion vectors using Parquet format

## Installation

### Prerequisites

- Python 3.10+ (recommended: 3.10.18)
- Conda (recommended for environment management)

### Setup

#### Option 1: Using Conda (Recommended)

```bash
uv sync
```

#### Option 2: Using pip

```bash
# Ensure Python 3.10+
python --version

# Install dependencies
pip install -r requirements.txt
```

### Environment Configuration

Create a `.env` file in the `llm/` directory:

```bash
API_KEY=your_api_key_here
BASE_URL=https://llmapi.paratera.com/v1
```

**Note**: 
- The `.env` file should only contain `API_KEY` and `BASE_URL`
- Model names are specified in code, not as environment variables
- Configuration is managed through the `llm.config` module

### Verify Installation

Run the environment check script:

```bash
python scripts/check_environment.py
```

#### ÁÇπÊ†áÁ≠æÊ®°ÂùóÊµãËØï
You should see:
- ‚úÖ Python version: 3.10.18
- ‚úÖ All required dependencies installed
- ‚úÖ API configuration correct

## Quick Start

# ÊµãËØïËÆ∞ÂøÜÊ∑±Â∫¶ÂíåÊ∏©Â∫¶ËÆ°ÁÆó
python -m test.test_labels

# ÊµãËØïÊÉäËÆ∂ÂÄºËÆ°ÁÆó
python -m test.test_speed
```

#### ÂÆû‰ΩìÊäΩÂèñÊµãËØï

```bash
# ÊµãËØïÂÆû‰ΩìÊäΩÂèñÂäüËÉΩ
python -m test.test_entity
```

#### ÂèåÊõ≤Á©∫Èó¥Ê®°ÂùóÊµãËØï

```bash
# ÊµãËØïÂèåÊõ≤Á©∫Èó¥Â≠òÂÇ®ÂíåÊ£ÄÁ¥¢
python -m test.test_poincare

# ÊµãËØïÂèåÊõ≤Á©∫Èó¥ÈìæÊé•
python -m test.test_linking
```

#### Êï¥ÂêàÊµãËØï

```bash
# ÊµãËØï HippoRAG Êï¥ÂêàÔºàÂ∞èÊ†∑Êú¨Êï∞ÊçÆÔºâ
python -m test.test_integration

# ÊµãËØïÊï∞ÊçÆÈõÜÊï¥ÂêàÔºàÁúüÂÆûÊï∞ÊçÆÈõÜÔºâ
python -m test.test_dataset_integration
```

## ‰∏ªË¶ÅÊ®°ÂùóËØ¥Êòé

### llm Ê®°Âùó

- **`llm/config.py`**ÔºöÁªü‰∏ÄÁÆ°ÁêÜ API ÈÖçÁΩÆÔºå‰ªé `.env` Êñá‰ª∂ËØªÂèñ `API_KEY` Âíå `BASE_URL`
- **`llm/completion_client.py`**ÔºöLLM ÂÆ¢Êà∑Á´ØÂ∞ÅË£Ö
  - `CompletionClient`ÔºöÊîØÊåÅ normal Âíå specific ‰∏§ÁßçÊ®°Âºè
  - `create_client()`Ôºö‰æøÊç∑ÂáΩÊï∞ÂàõÂª∫ÂÆ¢Êà∑Á´Ø
  - `ChatResult`ÔºöÊôÆÈÄöÂØπËØùÁªìÊûúÔºànormal Ê®°ÂºèÔºâ
  - `CompletionResult`ÔºöÂ∏¶ token Ê¶ÇÁéáÁöÑÁªìÊûúÔºàspecific Ê®°ÂºèÔºâ

### point_label Ê®°Âùó

ÁÇπÊ†áÁ≠æÊ®°ÂùóÊèê‰æõ‰∫ÜÂ§öÁßçÊñáÊú¨ÁâπÂæÅÊèêÂèñÂäüËÉΩÔºö

- **`point_label/emotion.py`**ÔºöÊÉÖÊÑüÂêëÈáèÊèêÂèñ
  - `Emotion` Á±ªÔºöËæìÂÖ• chunkÔºåËæìÂá∫ 30 Áª¥ÊÉÖÊÑüÂêëÈáèÔºàÂΩí‰∏ÄÂåñÔºâ
  - Âü∫‰∫é Plutchik ÊÉÖÁª™ËΩÆÂíåÊâ©Â±ïÊÉÖÁª™ÂàóË°®

- **`point_label/labels.py`**ÔºöËÆ∞ÂøÜÊ∑±Â∫¶ÂíåÊ∏©Â∫¶ËÆ°ÁÆó
  - `Labels` Á±ªÔºöËæìÂÖ• chunkÔºåËæìÂá∫ `LabelsResult`ÔºàÂåÖÂê´ emotion_vector, memory_depth, temperatureÔºâ
  - `memory_depth`ÔºöËÆ∞ÂøÜÊ∑±Â∫¶ = Á∫ØÂ∫¶ √ó ÂΩí‰∏ÄÂåñÊ®°ÈïøÔºà0~1Ôºâ
  - `temperature`ÔºöÊ∏©Â∫¶ = f(Á∫ØÂ∫¶, Âõ∞ÊÉëÂ∫¶)ÔºåË°®Á§∫ÊÉÖÁª™Ê≥¢Âä®Á®ãÂ∫¶Ôºà‰ªÖÂú® `use_specific=True` Êó∂ËÆ°ÁÆóÔºâ

- **`point_label/speed.py`**ÔºöÊÉäËÆ∂ÂÄºËÆ°ÁÆó
  - `Speed` Á±ªÔºöËæìÂÖ• chunkÔºåËæìÂá∫ÊÉäËÆ∂ÂÄºÔºàsurprise valueÔºâ
  - Âü∫‰∫é‰ø°ÊÅØËÆ∫ÁöÑ surprisalÔºö`surprisal = -log(p)`
  - ÊîØÊåÅÂ§öÁßçËÅöÂêàÊñπÂºèÔºömeanÔºàÊé®ËçêÔºâ„ÄÅsum„ÄÅmax„ÄÅgeometric_mean

### poincare Ê®°Âùó

ÂèåÊõ≤Á©∫Èó¥Â≠òÂÇ®‰∏éÊ£ÄÁ¥¢Ê®°ÂùóÔºåÂÆûÁé∞Âü∫‰∫é Poincar√© ÁêÉÁöÑÊÉÖÁª™ËÆ∞ÂøÜÁ≥ªÁªüÔºö

- **`poincare/types.py`**ÔºöÊï∞ÊçÆÁ±ªÂûãÂÆö‰πâ
  - `Point`ÔºöÂèåÊõ≤Á©∫Èó¥‰∏≠ÁöÑÁÇπÔºàÂåÖÂê´‰ΩçÁΩÆ„ÄÅÈÄüÂ∫¶„ÄÅÊó∂Èó¥Á≠âÂ±ûÊÄßÔºâ
  - `SearchResult`ÔºöÊ£ÄÁ¥¢ÁªìÊûú

- **`poincare/physics.py`**ÔºöÂèåÊõ≤Á©∫Èó¥Áâ©ÁêÜËÆ°ÁÆó
  - `TimePhysics`ÔºöÊó∂Èó¥Áâ©ÁêÜËÆ°ÁÆó
  - `ParticleProjector`ÔºöÁ≤íÂ≠êÊäïÂΩ±Âô®

- **`poincare/storage.py`**ÔºöÂèåÊõ≤Á©∫Èó¥Â≠òÂÇ®
  - `HyperAmyStorage`ÔºöÂü∫‰∫é ChromaDB ÁöÑÂèåÊõ≤Á©∫Èó¥Â≠òÂÇ®

- **`poincare/retrieval.py`**ÔºöÂèåÊõ≤Á©∫Èó¥Ê£ÄÁ¥¢
  - `HyperAmyRetrieval`ÔºöÊ∑∑ÂêàÊ£ÄÁ¥¢ÔºàËØ≠‰πâÊ£ÄÁ¥¢ + ÂèåÊõ≤Á©∫Èó¥Ê£ÄÁ¥¢Ôºâ

- **`poincare/linking.py`**ÔºöÂèåÊõ≤Á©∫Èó¥ÈìæÊé•ÊûÑÂª∫
  - `build_hyperbolic_links`ÔºöÊûÑÂª∫ÂèåÊõ≤Á©∫Èó¥ÈìæÊé•
  - `update_points_with_links`ÔºöÊõ¥Êñ∞ÁÇπÁöÑÈìæÊé•‰ø°ÊÅØ
  - `auto_link_points`ÔºöËá™Âä®ÈìæÊé•ÁÇπ

### utils Ê®°Âùó

- **`utils/extract_entitiy.py`**ÔºöÂÆû‰ΩìÊäΩÂèñ
  - `Entity` Á±ªÔºöÂü∫‰∫é HippoRAG ÁöÑ OpenIE Ê®°Âùó
  - `extract_entities()`ÔºöÊèêÂèñÂëΩÂêçÂÆû‰Ωì
  - `extract_triples()`ÔºöÊèêÂèñ‰∏âÂÖÉÁªÑÔºàÂÆû‰Ωì-ÂÖ≥Á≥ª-ÂÆû‰ΩìÔºâ
  - `extract_all()`ÔºöÂêåÊó∂ÊèêÂèñÂÆû‰ΩìÂíå‰∏âÂÖÉÁªÑ

### sentiment Ê®°ÂùóÔºàÊóßÁâàÔºå‰øùÁïôÂÖºÂÆπÔºâ

- **`sentiment/emotion_vector.py`**Ôºö‰ªéÊñáÊú¨‰∏≠ÊèêÂèñÊÉÖÊÑüÂêëÈáè
- **`sentiment/emotion_store.py`**ÔºöÊÉÖÊÑüÂêëÈáèÁöÑÂ≠òÂÇ®ÂíåÁÆ°ÁêÜ
- **`sentiment/hipporag_enhanced.py`**ÔºöÂ¢ûÂº∫Áâà HippoRAGÔºåÈõÜÊàêÊÉÖÊÑüÂàÜÊûêÂäüËÉΩ

## ‰ΩøÁî®Á§∫‰æã

### Âü∫Êú¨‰ΩøÁî®
### Basic Usage

#### Using LLM Client

```python
from llm import create_client
from llm.config import DEFAULT_MODEL

# Create client
client = create_client(model_name=DEFAULT_MODEL)

# Normal mode (default) - Chat Completions API
result = client.complete("What is Python?")
print(result.get_answer_text())

# Specific mode - Token probability analysis
result = client.complete("What is the capital of China?", mode="specific")
result.print_analysis()  # Print token probability analysis
```

#### Using Emotion-Enhanced RAG

```python
from point_label.emotion import Emotion

# ÊèêÂèñÊÉÖÊÑüÂêëÈáè
emotion = Emotion()
chunk = "I'm very happy!"
vector = emotion.extract(chunk)
print(f"Emotion Vector: {vector}")  # 30 Áª¥ÂêëÈáè
```

### ‰ΩøÁî®ËÆ∞ÂøÜÊ∑±Â∫¶ÂíåÊ∏©Â∫¶

```python
from point_label.labels import Labels

# ÊèêÂèñËÆ∞ÂøÜÊ∑±Â∫¶ÂíåÊ∏©Â∫¶
labels = Labels()
chunk = "I'm very happy!"
result = labels.extract(chunk, use_specific=True)

print(f"Emotion Vector: {result.emotion_vector}")
print(f"Memory Depth: {result.memory_depth}")  # 0~1ÔºåË∂äÂ§ßË∂äÊ∑±Âàª
print(f"Temperature: {result.temperature}")    # 0~1ÔºåË∂äÂ§ßÊ≥¢Âä®Ë∂äÂ§ß
```

### ‰ΩøÁî®ÊÉäËÆ∂ÂÄº

```python
from point_label.speed import Speed

# ËÆ°ÁÆóÊÉäËÆ∂ÂÄº
speed = Speed()
chunk = "Quantum entanglement overturns our understanding of reality!"
surprise = speed.extract(chunk, aggregation="mean")
print(f"Surprise Value: {surprise}")  # ÂÄºË∂äÂ§ßË∂äÊÑèÂ§ñ/ÈáçË¶Å
```

### ‰ΩøÁî®ÂÆû‰ΩìÊäΩÂèñ

```python
from utils.extract_entitiy import Entity

# ÊèêÂèñÂÆû‰ΩìÂíå‰∏âÂÖÉÁªÑ
entity = Entity()
chunk = "Barack Obama was the 44th president of the United States."

# ÊèêÂèñÂÆû‰Ωì
entities = entity.extract_entities(chunk)
print(f"Entities: {entities}")  # ['Barack Obama', 'United States']

# ÊèêÂèñ‰∏âÂÖÉÁªÑ
triples = entity.extract_triples(chunk)
print(f"Triples: {triples}")  # [['Barack Obama', 'was', '44th president'], ...]

# ÂêåÊó∂ÊèêÂèñ
result = entity.extract_all(chunk)
print(f"Entities: {result['entities']}")
print(f"Triples: {result['triples']}")
```

### ‰ΩøÁî®ÂèåÊõ≤Á©∫Èó¥Â≠òÂÇ®ÂíåÊ£ÄÁ¥¢

```python
from poincare import HyperAmyStorage, HyperAmyRetrieval

# ÂàõÂª∫Â≠òÂÇ®
storage = HyperAmyStorage(db_path="./hyperamy_db")

# Â≠òÂÇ®ÁÇπ
point = Point(
    content="I'm very happy!",
    emotion_vector=emotion_vector,
    memory_depth=0.8,
    temperature=0.2
)
storage.add_point(point)

# ÂàõÂª∫Ê£ÄÁ¥¢Âô®
retrieval = HyperAmyRetrieval(storage)

# Ê£ÄÁ¥¢
query = "happy"
results = retrieval.search(query, top_k=5)
for result in results:
    print(f"Content: {result.content}, Score: {result.score}")
```

### ‰ΩøÁî®ÊÉÖÊÑüÂ¢ûÂº∫ÁöÑ HippoRAG

```python
from sentiment.hipporag_enhanced import HippoRAGEnhanced
from hipporag.utils.config_utils import BaseConfig
from llm.config import BASE_URL, DEFAULT_MODEL, DEFAULT_EMBEDDING_MODEL

# Configure models
config = BaseConfig(
    save_dir="./outputs",
    llm_base_url=BASE_URL,
    llm_name=DEFAULT_MODEL,
    embedding_model_name=DEFAULT_EMBEDDING_MODEL,
    embedding_base_url=BASE_URL,
)

# Create emotion-enhanced HippoRAG
hipporag = HippoRAGEnhanced(
    global_config=config,
    enable_emotion=True,
    emotion_weight=0.3,  # 30% emotion, 70% semantic
    emotion_model_name=DEFAULT_MODEL
)

# Index documents
docs = [
    "I'm thrilled about winning the competition! This is amazing!",
    "I'm devastated by the loss. Everything feels hopeless.",
    "The weather is nice today. It's a beautiful sunny day."
]
hipporag.index(docs=docs)

# Retrieve with emotion enhancement
queries = ["What makes people feel happy?", "What causes sadness?"]
results = hipporag.retrieve(queries=queries, num_to_retrieve=2)

# RAG QA with emotion awareness
qa_results, messages, metadata = hipporag.rag_qa(queries=queries)
```

## Project Structure

1. **ÊµãËØïËøêË°åÊñπÂºè**ÔºöÂßãÁªàÂú®È°πÁõÆÊ†πÁõÆÂΩï‰∏ã‰ΩøÁî® `python -m test.xxx` ËøêË°åÊµãËØïÔºå‰∏çË¶Å‰øÆÊîπ `sys.path` Êàñ‰ΩøÁî® `os.path`
2. **ÈÖçÁΩÆÁÆ°ÁêÜ**ÔºöÊâÄÊúâÈÖçÁΩÆÈÄöËøá `llm.config` Ê®°ÂùóËÆøÈóÆÔºå‰∏çË¶ÅÁõ¥Êé•ËØªÂèñÁéØÂ¢ÉÂèòÈáè
3. **Ê®°ÂºèÈÄâÊã©**ÔºöÈªòËÆ§‰ΩøÁî® `normal` Ê®°ÂºèÔºàÊôÆÈÄöÂØπËØùÔºâÔºåÈúÄË¶Å token Ê¶ÇÁéáÊó∂‰ΩøÁî® `mode="specific"`
4. **Ê®°ÂûãÂêçÁß∞**ÔºöÊ®°ÂûãÂêçÁß∞Âú®‰ª£Á†Å‰∏≠Ëá™ÂÆö‰πâÔºå‰∏ç‰Ωú‰∏∫ÁéØÂ¢ÉÂèòÈáèÔºåÂèØ‰ª•‰ΩøÁî® `DEFAULT_MODEL` Âíå `DEFAULT_EMBEDDING_MODEL` ‰Ωú‰∏∫ÈªòËÆ§ÂÄº
5. **ËÆ∞ÂøÜÊ∑±Â∫¶ËÆ°ÁÆó**Ôºö`memory_depth = purity √ó normalized_magnitude`ÔºåÂÖ∂‰∏≠Á∫ØÂ∫¶ = max(emotion_vector) / sum(emotion_vector)
6. **Ê∏©Â∫¶ËÆ°ÁÆó**Ôºö‰ªÖÂú® `use_specific=True` Êó∂ËÆ°ÁÆóÔºåÈúÄË¶Å token Ê¶ÇÁéá‰ø°ÊÅØ

## Core Modules

- `requests`ÔºöHTTP ËØ∑Ê±Ç
- `python-dotenv`ÔºöÁéØÂ¢ÉÂèòÈáèÁÆ°ÁêÜ
- `numpy`ÔºöÊï∞ÂÄºËÆ°ÁÆó
- `pandas`ÔºöÊï∞ÊçÆÂ§ÑÁêÜ
- `chromadb`ÔºöÂêëÈáèÊï∞ÊçÆÂ∫ì
- `hipporag`ÔºöÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÊ°ÜÊû∂ÔºàÂ§ñÈÉ®‰æùËµñÔºâ

## ÁâàÊú¨ÂéÜÂè≤

- **v1.2.0**ÔºöÊ∑ªÂä†ÂèåÊõ≤Á©∫Èó¥Â≠òÂÇ®‰∏éÊ£ÄÁ¥¢Ê®°ÂùóÔºàpoincareÔºâ
- **v1.1.0**ÔºöÊ∑ªÂä†ÁÇπÊ†áÁ≠æÊ®°ÂùóÔºàpoint_labelÔºâÂíåÂÆû‰ΩìÊäΩÂèñÊ®°ÂùóÔºàutilsÔºâ
- **v1.0.0**ÔºöÂàùÂßãÁâàÊú¨ÔºåÂåÖÂê´ LLM ÂÆ¢Êà∑Á´ØÂíåÊÉÖÊÑüÂàÜÊûêÊ®°Âùó
### `sentiment` Module

The emotion analysis module provides:

- **`emotion_vector.py`**: Extracts 28-dimensional emotion vectors from text using LLMs
- **`emotion_store.py`**: Manages persistent storage of emotion vectors using Parquet format
- **`hipporag_enhanced.py`**: `HippoRAGEnhanced` class that extends `HippoRAG` with emotion analysis

### `llm` Module

The LLM client module provides:

- **`completion_client.py`**: 
  - `CompletionClient`: Supports normal and specific modes
  - `create_client()`: Convenience function to create clients
  - `ChatResult`: Results for normal mode (Chat Completions API)
  - `CompletionResult`: Results for specific mode with token probabilities
- **`config.py`**: Unified API configuration management

### `hipporag` Module

The core RAG framework (based on [HippoRAG](https://github.com/OSU-NLP-Group/HippoRAG)):

- **`HippoRAG.py`**: Main RAG framework class
- **`embedding_store.py`**: Embedding vector storage
- **`embedding_model/`**: Support for various embedding models (OpenAI, NV-Embed-v2, etc.)
- **`llm/`**: LLM inference classes (OpenAI GPT, Bedrock, Transformers, vLLM)
- **`evaluation/`**: Evaluation metrics for retrieval and QA

## Running Tests

**Important**: All tests should be run from the project root directory using `python -m`:

### Basic Tests

```bash
# Test token probability analysis (specific mode)
python -m test.test_infer

# Test Completion Client functionality
python -m test.test_completion_client
```

### Emotion Analysis Tests

```bash
# Test emotion vector extraction
python -m test.test_emotion

# Test BGE embedding and emotion description
python -m test.test_bge
```

### Integration Tests

```bash
# Test HippoRAG integration (small sample)
python -m test.test_integration

# Test dataset integration (real dataset)
python -m test.test_dataset_integration
```

## Usage Examples

### Example 1: Emotion Vector Extraction

```python
from sentiment.emotion_vector import EmotionExtractor

extractor = EmotionExtractor()
text = "I'm so happy and excited about this news!"
emotion_vector = extractor.extract_emotion_vector(text)
print(f"Emotion vector: {emotion_vector}")
```

### Example 2: Emotion-Enhanced Retrieval

```python
from sentiment.hipporag_enhanced import HippoRAGEnhanced
from hipporag.utils.config_utils import BaseConfig

# Initialize with emotion enhancement
config = BaseConfig(
    save_dir="./outputs",
    llm_base_url="https://llmapi.paratera.com/v1",
    llm_name="DeepSeek-V3.2",
    embedding_model_name="GLM-Embedding-2",
)

hipporag = HippoRAGEnhanced(
    global_config=config,
    enable_emotion=True,
    emotion_weight=0.3,  # Adjust emotion vs semantic weight
)

# Index documents
hipporag.index(docs=your_documents)

# Retrieve with emotion awareness
results = hipporag.retrieve(queries=your_queries)
```

### Example 3: Token Probability Analysis

```python
from llm import create_client

client = create_client(model_name="DeepSeek-V3.2")

# Get token-level probabilities
result = client.complete(
    "Explain quantum computing",
    mode="specific"
)

# Analyze token probabilities
result.print_analysis()
```

## Dependencies

### Required Dependencies

All required dependencies are listed in `requirements.txt`:

- `requests>=2.32.0`: HTTP requests
- `python-dotenv>=1.1.0`: Environment variable management
- `numpy>=1.26.0`: Numerical computing
- `pandas>=2.0.0`: Data processing
- `openai>=1.91.0`: OpenAI API client
- `httpx>=0.28.0`: Async HTTP client
- `pyarrow>=14.0.0` or `fastparquet>=2025.12.0`: Parquet file support
- `python-igraph>=0.11.0`: Graph processing
- `tenacity>=8.5.0`: Retry mechanism
- `tqdm>=4.66.0`: Progress bars

### Optional Dependencies

Install based on your use case:

- `transformers>=4.45.0`: Transformers model support
- `sentence-transformers>=2.2.0`: Sentence Transformers embedding
- `litellm>=1.73.0`: Bedrock support
- `torch>=2.0.0`: PyTorch support
- `vllm>=0.2.0`: VLLM offline inference
- `gritlm>=1.0.0`: GritLM embedding
- `outlines>=0.0.1`: Transformers offline mode

## Environment Alignment

To ensure consistent environments across collaborators:

1. **Use the same Python version**: Python 3.10.18
2. **Use the same dependency versions**: Run `pip install -r requirements.txt`
3. **Verify environment**: Run `python scripts/check_environment.py`

## Code Structure

The project follows a modular structure:

- **`sentiment/`**: Emotion analysis functionality
- **`llm/`**: LLM client and configuration
- **`hipporag/`**: Core RAG framework (based on HippoRAG)
- **`test/`**: Test suites for all modules
- **`scripts/`**: Utility scripts

## Key Differences from HippoRAG

HyperAmy extends HippoRAG with:

1. **Emotion Analysis**: 28-dimensional emotion vector extraction
2. **Emotion-Enhanced Retrieval**: Combines semantic and emotional similarity
3. **Emotion Storage**: Persistent storage of emotion vectors
4. **Token Probability**: Support for token-level probability analysis
5. **Enhanced API**: Improved error handling and robustness

## Notes

1. **Test Execution**: Always run tests from the project root using `python -m test.xxx`
2. **Configuration Management**: All configuration is accessed through `llm.config` module
3. **Mode Selection**: Default is `normal` mode (chat), use `mode="specific"` for token probabilities
4. **Model Names**: Model names are specified in code, not as environment variables

## Contributing

We welcome contributions! Please ensure:

1. Code follows Python 3.10+ standards
2. All tests pass
3. Environment alignment (use `requirements.txt`)
4. Documentation is updated

## Related Work

- [HippoRAG](https://github.com/OSU-NLP-Group/HippoRAG): The base RAG framework that HyperAmy extends
- [HippoRAG Paper](https://arxiv.org/abs/2405.14831): Original HippoRAG paper

## Citation

If you use HyperAmy in your research, please cite:

```bibtex
@misc{hyperamy2024,
  title={HyperAmy: Emotion-Enhanced RAG Framework},
  author={HyperAmy Contributors},
  year={2024},
  url={https://github.com/sherkevin/HyperAmy}
}
```

And the base HippoRAG framework:

```bibtex
@inproceedings{guti√©rrez2024hipporag,
  title={HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models}, 
  author={Bernal Jim√©nez Guti√©rrez and Yiheng Shu and Yu Gu and Michihiro Yasunaga and Yu Su},
  booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year={2024},
  url={https://openreview.net/forum?id=hkujvAPVsg}
}
```

## License

MIT License - see LICENSE file for details

## Contact

Questions or issues? Please file an issue on [GitHub](https://github.com/sherkevin/HyperAmy/issues).

---

**HyperAmy**: Emotion-Enhanced RAG Framework built on HippoRAG
