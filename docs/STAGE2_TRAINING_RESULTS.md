# 二阶段训练实验结果报告

## 实验概述

本次实验完成了二阶段训练（难例对齐）的完整流程，包括数据构造、模型评估、难例筛选和对比学习训练。

## 实验配置

- **数据集**: Game of Thrones QA数据
  - QA对数量: 50
  - Chunks数据: 1,231个
  - 实体标注: 1,463个
- **设备**: GPU (NVIDIA L20)
- **负样本数**: 每个QA对5个负样本contexts
- **难例阈值**: Top-3 (ground truth不在top-3中)

## 阶段1: 数据构造和评估

### 数据构造结果

- **构造样本数**: 50个
- **每个样本包含**: 1个ground truth context + 5个负样本contexts
- **总文本处理数**: 350个 (50 Q + 300 contexts)

### 模型性能评估（训练前）

| 指标 | 结果 | 说明 |
|------|------|------|
| Top-1准确率 | 10.0% (5/50) | Ground truth context在预测排序的第1位 |
| Top-3准确率 | 30.0% (15/50) | Ground truth context在预测排序的前3位 |
| Top-5准确率 | 76.0% (38/50) | Ground truth context在预测排序的前5位 |
| 难例数量 | 35个 (70.0%) | Ground truth不在top-3中的样本 |

### 关键发现

1. **Top-1准确率较低**: 仅10%，说明模型在精确匹配上还有很大改进空间
2. **Top-5准确率较高**: 76%，说明模型能够识别相关contexts，但排序不够精确
3. **难例比例高**: 70%的样本被识别为难例，说明二阶段训练非常必要

## 阶段2: 对比学习训练

### 训练配置

- **难例数量**: 35个
- **Batch size**: 8
- **Epochs**: 5
- **Learning rate**: 1e-5
- **Margin**: 0.1
- **Loss函数**: Ranking Loss (margin ranking loss)

### 训练结果

#### Loss曲线

| Epoch | Loss | 下降幅度 |
|-------|------|----------|
| 1 | 0.0998 | - |
| 2 | 0.0848 | ↓ 15.0% |
| 3 | 0.0707 | ↓ 16.6% |
| 4 | 0.0632 | ↓ 10.6% |
| 5 | 0.0527 | ↓ 16.6% |

**总Loss下降**: 47.2% (从0.0998降到0.0527)

#### 训练特点

- ✅ Loss持续稳定下降，无过拟合迹象
- ✅ 训练速度快（GPU加速，每个epoch约4-5秒）
- ✅ 模型收敛良好

### 训练时间

- **数据构造和评估**: ~6秒 (GPU加速)
- **对比学习训练**: ~27秒 (5个epochs)
- **总时间**: ~33秒

## 输出文件

### 远程服务器位置

`/public/jiangh/stage2_training/`

### 文件列表

1. **constructed_data.jsonl** (477KB)
   - 构造的Q+Contexts数据
   - 50个样本

2. **evaluation_results.json** (41KB)
   - 评估结果详情
   - 包含每个样本的预测排序、相似度分数、一致性指标

3. **hard_negatives.jsonl** (334KB)
   - 筛选出的难例数据
   - 35个样本

4. **checkpoints/** (每个477MB)
   - `epoch_1.pt` ~ `epoch_5.pt`: 每个epoch的checkpoint
   - `best_model_stage2.pt`: 最终训练好的模型

## 关键发现总结

### 1. 模型当前性能

- **精确匹配能力弱**: Top-1准确率仅10%，说明模型在区分最相关context方面还有很大改进空间
- **相关识别能力好**: Top-5准确率76%，说明模型能够识别相关contexts
- **排序精度不足**: 虽然能识别相关contexts，但排序不够精确

### 2. 训练效果

- **Loss持续下降**: 从0.0998降到0.0527，下降47.2%
- **训练稳定**: 无过拟合迹象，模型收敛良好
- **训练高效**: GPU加速下，5个epochs仅用27秒

### 3. 难例分析

- **难例比例高**: 70%的样本被识别为难例，说明：
  - 当前模型在QA检索任务上还有很大改进空间
  - 二阶段训练非常必要
  - 对比学习能够针对性地改进这些难例

## 下一步建议

### 1. 模型评估

使用训练好的模型 (`best_model_stage2.pt`) 重新评估，检查性能是否提升：
- 在相同的50个QA对上重新运行评估
- 对比训练前后的Top-K准确率
- 分析难例是否减少

### 2. 超参数调优

- **增加训练epochs**: 当前5个epochs可能不够，可以尝试10-20个epochs
- **调整learning rate**: 当前1e-5可能偏小，可以尝试5e-5或1e-4
- **调整margin**: 当前0.1，可以尝试0.2或0.05

### 3. 数据扩展

- **增加负样本数**: 当前每个QA对5个负样本，可以增加到10-20个
- **使用更多QA对**: 当前50个，可以扩展到全部QA数据
- **增加难例阈值**: 当前Top-3，可以尝试Top-5或Top-10

### 4. 模型集成

- 将二阶段训练好的模型与阶段一模型结合
- 在QA检索任务上测试整体性能
- 对比不同训练策略的效果

## 技术细节

### 相似度计算

- 使用实体级别的cosine相似度
- 如果Q或Context没有实体标注，回退到句子级别的相似度
- 计算Q的所有实体与Context的所有实体的平均相似度

### Ranking Loss

- 使用margin ranking loss
- 对于contexts列表 [c1, c2, ..., cn]（按ground truth顺序），
  希望 sim(Q, c1) > sim(Q, c2) > ... > sim(Q, cn)
- Loss = max(0, margin - (sim_i - sim_j)) 对所有 i < j 的pair

### 模型架构

- 使用阶段一训练好的ProbabilisticGBERTV4模型
- 64维embedding空间
- 句子级别的mu向量用于相似度计算

## 实验时间线

- **开始时间**: 2026-01-13 14:46:28
- **数据构造完成**: 2026-01-13 14:46:34
- **评估完成**: 2026-01-13 14:46:34
- **训练开始**: 2026-01-13 14:48:51
- **训练完成**: 2026-01-13 14:49:18
- **总耗时**: ~33秒

---

*报告生成时间: 2026-01-13*
*实验位置: 远程服务器 (jiangh@10.103.92.120:1066)*
